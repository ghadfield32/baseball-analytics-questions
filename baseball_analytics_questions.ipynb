{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseball Analytics Technical Questions\n",
    "\n",
    "This notebook contains solutions to baseball analytics interview questions covering:\n",
    "- Q1: Streaming pitch data with rolling features\n",
    "- Q2: Model serving with batched inference\n",
    "- Q3: SQL deduplication queries\n",
    "- Q4: System design for ML pipeline\n",
    "- Q5: In-game win probability updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q1 – Streaming Pitch Data → Rolling Features\n",
    "\n",
    "**Problem**: Maintain per-pitcher rolling statistics over the last 100 pitches from a stream of pitch events.\n",
    "\n",
    "**Requirements**:\n",
    "- Rolling average velocity\n",
    "- Rolling zone rate (is_in_zone)\n",
    "- Rolling whiff rate (is_whiff over swings)\n",
    "- O(1) amortized update time\n",
    "- Bounded memory\n",
    "- Handle multiple pitchers interleaved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseball Analytics Q1 - Rolling Pitch Statistics\n",
      "============================================================\n",
      "\n",
      "Processing 300 pitches from 3 pitchers...\n",
      "\n",
      "============================================================\n",
      "Final Rolling Statistics (last 100 pitches per pitcher)\n",
      "============================================================\n",
      "\n",
      "P1:\n",
      "  Pitch Count:     100\n",
      "  Avg Velocity:    91.4 mph\n",
      "  Zone Rate:       37.0%\n",
      "  Whiff Rate:      18.4%\n",
      "\n",
      "P2:\n",
      "  Pitch Count:     89\n",
      "  Avg Velocity:    91.7 mph\n",
      "  Zone Rate:       48.3%\n",
      "  Whiff Rate:      20.5%\n",
      "\n",
      "P3:\n",
      "  Pitch Count:     100\n",
      "  Avg Velocity:    91.5 mph\n",
      "  Zone Rate:       52.0%\n",
      "  Whiff Rate:      22.7%\n",
      "\n",
      "============================================================\n",
      "[OK] All pitchers processed with O(1) amortized updates\n",
      "[OK] Memory bounded at 100 pitches per pitcher\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Q1 - Streaming Pitch Data → Rolling Features\n",
    "\n",
    "Maintain per-pitcher rolling statistics over the last 100 pitches.\n",
    "O(1) amortized updates with bounded memory.\n",
    "\"\"\"\n",
    "\n",
    "from collections import deque, defaultdict\n",
    "import random\n",
    "\n",
    "\n",
    "class PitcherRollingStats:\n",
    "    def __init__(self, window=100):\n",
    "        \"\"\"\n",
    "        Initialize the rolling stats tracker.\n",
    "\n",
    "        Args:\n",
    "            window: Number of recent pitches to track (default: 100)\n",
    "        \"\"\"\n",
    "        self.window = window\n",
    "        self.pitch_data = defaultdict(lambda: deque(maxlen=self.window))\n",
    "\n",
    "    def update(self, event):\n",
    "        \"\"\"\n",
    "        Ingest one pitch event and return current rolling stats for that pitcher.\n",
    "\n",
    "        Args:\n",
    "            event: dict with keys: game_id, pitcher_id, batter_id, inning,\n",
    "                   pitch_number, pitch_type, velocity, spin_rate, is_in_zone,\n",
    "                   is_swing, is_ball_in_play, is_strike, is_whiff\n",
    "\n",
    "        Returns:\n",
    "            dict: Rolling statistics for the pitcher\n",
    "        \"\"\"\n",
    "        pitcher_id = event['pitcher_id']\n",
    "        dq = self.pitch_data[pitcher_id]\n",
    "        dq.append(event)  # auto-pops from left if >100\n",
    "\n",
    "        # Compute rolling average velocity\n",
    "        total_vel = sum(p['velocity'] for p in dq)\n",
    "        mean_vel = total_vel / len(dq)\n",
    "\n",
    "        # Zone rate: fraction where is_in_zone == 1\n",
    "        in_zone_count = sum(p['is_in_zone'] for p in dq)\n",
    "        zone_rate = in_zone_count / len(dq)\n",
    "\n",
    "        # Whiff rate: whiffs / swings, but only for pitches with is_swing\n",
    "        swings = sum(p['is_swing'] for p in dq)\n",
    "        whiffs = sum(p['is_whiff'] for p in dq)\n",
    "        whiff_rate = (whiffs / swings) if swings > 0 else 0.0\n",
    "\n",
    "        return {\n",
    "            'pitcher_id': pitcher_id,\n",
    "            'mean_velocity': mean_vel,\n",
    "            'zone_rate': zone_rate,\n",
    "            'whiff_rate': whiff_rate,\n",
    "            'pitch_count': len(dq)\n",
    "        }\n",
    "\n",
    "\n",
    "def generate_sample_pitch():\n",
    "    \"\"\"Generate a single sample pitch event.\"\"\"\n",
    "    pitch_types = ['FF', 'SL', 'CH', 'CU', 'SI']\n",
    "    is_swing = random.random() < 0.45\n",
    "    is_whiff = is_swing and (random.random() < 0.25)\n",
    "\n",
    "    return {\n",
    "        'game_id': f\"G{random.randint(1, 5)}\",\n",
    "        'pitcher_id': f\"P{random.randint(1, 3)}\",\n",
    "        'batter_id': f\"B{random.randint(1, 20)}\",\n",
    "        'inning': random.randint(1, 9),\n",
    "        'pitch_number': 0,  # Will be set by caller\n",
    "        'pitch_type': random.choice(pitch_types),\n",
    "        'velocity': round(random.uniform(85, 98), 1),\n",
    "        'spin_rate': random.randint(2000, 2800),\n",
    "        'is_in_zone': random.random() < 0.48,\n",
    "        'is_swing': is_swing,\n",
    "        'is_ball_in_play': is_swing and (random.random() < 0.75),\n",
    "        'is_strike': random.random() < 0.52,\n",
    "        'is_whiff': is_whiff\n",
    "    }\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Example usage of PitcherRollingStats.\"\"\"\n",
    "    print(\"Baseball Analytics Q1 - Rolling Pitch Statistics\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    # Initialize tracker\n",
    "    stats_tracker = PitcherRollingStats(window=100)\n",
    "\n",
    "    # Simulate pitch stream\n",
    "    num_pitches = 300\n",
    "    print(f\"\\nProcessing {num_pitches} pitches from 3 pitchers...\")\n",
    "\n",
    "    pitcher_stats = {}\n",
    "\n",
    "    for i in range(num_pitches):\n",
    "        pitch = generate_sample_pitch()\n",
    "        pitch['pitch_number'] = i\n",
    "\n",
    "        stats = stats_tracker.update(pitch)\n",
    "        pitcher_stats[stats['pitcher_id']] = stats\n",
    "\n",
    "    # Display final results\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Final Rolling Statistics (last 100 pitches per pitcher)\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    for pitcher_id in sorted(pitcher_stats.keys()):\n",
    "        stats = pitcher_stats[pitcher_id]\n",
    "        print(f\"\\n{pitcher_id}:\")\n",
    "        print(f\"  Pitch Count:     {stats['pitch_count']}\")\n",
    "        print(f\"  Avg Velocity:    {stats['mean_velocity']:.1f} mph\")\n",
    "        print(f\"  Zone Rate:       {stats['zone_rate']:.1%}\")\n",
    "        print(f\"  Whiff Rate:      {stats['whiff_rate']:.1%}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"[OK] All pitchers processed with O(1) amortized updates\")\n",
    "    print(\"[OK] Memory bounded at 100 pitches per pitcher\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 – Model serving: batched inference API with timeouts\n",
    "\n",
    "You’re serving an xG-style model that takes fixed-length feature vectors for shots and returns a probability. You want to batch requests for GPU efficiency, but you also need latency under 100ms per request.\n",
    "\n",
    "Design a simple Python API layer (no need for full FastAPI boilerplate) that:\n",
    "\n",
    "Accepts individual prediction requests from multiple threads.\n",
    "\n",
    "Batches them into tensors of size up to 128.\n",
    "\n",
    "Ensures no request waits longer than 50ms in the queue before being run.\n",
    "\n",
    "Show:\n",
    "\n",
    "How you’d structure the worker thread / queue.\n",
    "\n",
    "A predict(features) function that a caller would use.\n",
    "\n",
    "How you’d handle shutdown cleanly.\n",
    "\n",
    "(This is exactly the kind of “bridge between Baseball Analytics models and Baseball Systems tools” they care about.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy path: [(1, 6), (7, 24)]\n",
      "Stress test: [(0, 3), (1, 6), (2, 9), (3, 12), (4, 15), (5, 18), (6, 21), (7, 24), (8, 27), (9, 30)]\n"
     ]
    }
   ],
   "source": [
    "from queue import Queue, Empty\n",
    "from threading import Thread, Event\n",
    "import time\n",
    "\n",
    "class PredictionRequest:\n",
    "    def __init__(self, features):\n",
    "        self.features = features\n",
    "        self.event = Event()\n",
    "        self.result = None\n",
    "\n",
    "class BatchedPredictor:\n",
    "    def __init__(self, model, max_batch_size=128, max_wait_ms=50):\n",
    "        self.model = model\n",
    "        self.max_batch_size = max_batch_size\n",
    "        self.max_wait_ms = max_wait_ms\n",
    "        self.queue = Queue()\n",
    "        self._stop = Event()\n",
    "        self.worker = Thread(target=self._batch_worker, daemon=True)\n",
    "        self.worker.start()\n",
    "\n",
    "    def predict(self, features):\n",
    "        req = PredictionRequest(features)\n",
    "        self.queue.put(req)\n",
    "        req.event.wait()\n",
    "        return req.result\n",
    "\n",
    "    def _batch_worker(self):\n",
    "        while not self._stop.is_set():\n",
    "            batch = []\n",
    "            batch_start = time.time()\n",
    "            try:\n",
    "                req = self.queue.get(timeout=0.05)\n",
    "                batch.append(req)\n",
    "                while len(batch) < self.max_batch_size:\n",
    "                    wait_time = self.max_wait_ms / 1000 - (time.time() - batch_start)\n",
    "                    if wait_time <= 0:\n",
    "                        break\n",
    "                    try:\n",
    "                        req = self.queue.get(timeout=wait_time)\n",
    "                        batch.append(req)\n",
    "                    except Empty:\n",
    "                        break\n",
    "            except Empty:\n",
    "                continue\n",
    "\n",
    "            if batch:\n",
    "                features_batch = [r.features for r in batch]\n",
    "                preds = self.model.predict(features_batch)\n",
    "                for req, pred in zip(batch, preds):\n",
    "                    req.result = pred\n",
    "                    req.event.set()\n",
    "\n",
    "    def shutdown(self):\n",
    "        self._stop.set()\n",
    "        self.worker.join()\n",
    "\n",
    "\n",
    "# Smoke test: simple dummy model\n",
    "class DummyModel:\n",
    "    def predict(self, batch):\n",
    "        return [sum(f) for f in batch]\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import threading\n",
    "\n",
    "    scorer = BatchedPredictor(DummyModel(), max_batch_size=4, max_wait_ms=20)\n",
    "\n",
    "    results = []\n",
    "    def worker(i):\n",
    "        out = scorer.predict([i, i+1, i+2])\n",
    "        results.append((i, out))\n",
    "\n",
    "    # Happy path: less than batch size\n",
    "    t1 = threading.Thread(target=worker, args=(1,))\n",
    "    t2 = threading.Thread(target=worker, args=(7,))\n",
    "    t1.start(); t2.start(); t1.join(); t2.join()\n",
    "    print(\"Happy path:\", results)\n",
    "\n",
    "    # Edge: lots of requests, check batching and no more than batch size per batch\n",
    "    results.clear()\n",
    "    threads = [threading.Thread(target=worker, args=(i,)) for i in range(10)]\n",
    "    for t in threads: t.start()\n",
    "    for t in threads: t.join()\n",
    "    print(\"Stress test:\", results)\n",
    "\n",
    "    scorer.shutdown()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q3 – SQL: Deduplicate and Choose Latest Model Version\n",
    "\n",
    "**Problem**: Query a model runs table to find the latest run per model version, then find the best version per family.\n",
    "\n",
    "**Schema**:\n",
    "```sql\n",
    "model_runs(\n",
    "  model_family   TEXT,\n",
    "  model_version  TEXT,\n",
    "  run_ts         TIMESTAMP,\n",
    "  elpd           DOUBLE PRECISION\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write SQL queries\n",
    "# Query 1: Latest run per (family, version)\n",
    "# Query 2: Best version by ELPD for each model_family\n",
    "import duckdb\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "-- Latest run per (model_family, model_version)\n",
    "SELECT\n",
    "  model_family,\n",
    "  model_version,\n",
    "  run_ts,\n",
    "  elpd\n",
    "FROM (\n",
    "  SELECT *,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY model_family, model_version\n",
    "      ORDER BY run_ts DESC\n",
    "    ) AS rn\n",
    "  FROM model_runs\n",
    ") t\n",
    "WHERE rn = 1;\n",
    "\n",
    "-- Best model_version per model_family by ELPD\n",
    "WITH latest_per_version AS (\n",
    "  SELECT *,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY model_family, model_version\n",
    "      ORDER BY run_ts DESC\n",
    "    ) AS rn\n",
    "  FROM model_runs\n",
    ")\n",
    "SELECT\n",
    "  model_family,\n",
    "  model_version,\n",
    "  run_ts,\n",
    "  elpd\n",
    "FROM (\n",
    "  SELECT *,\n",
    "    ROW_NUMBER() OVER (\n",
    "      PARTITION BY model_family\n",
    "      ORDER BY elpd DESC\n",
    "    ) AS r_best\n",
    "  FROM latest_per_version\n",
    "  WHERE rn = 1\n",
    ") x\n",
    "WHERE r_best = 1;\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q4 – System Design: End-to-End ML Pipeline\n",
    "\n",
    "**Problem**: Design a production ML pipeline for player projection models.\n",
    "\n",
    "**Requirements**:\n",
    "- Nightly data pulls from Snowflake\n",
    "- Model training/refresh based on drift/schedule\n",
    "- Evaluation vs current production model\n",
    "- Automated promotion and API exposure\n",
    "- Versioning, rollback, and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Design document or architecture diagram\n",
    "# Include: tools, versioning strategy, rollback plan, monitoring approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Q5 – Baseball-Flavored Coding: In-Game Win Probability Update\n",
    "\n",
    "**Problem**: Update win probability during a game based on plate appearance outcomes.\n",
    "\n",
    "**Inputs**:\n",
    "- Run expectancy table: (outs, base_state) → expected_runs_remaining\n",
    "- Before/after game states from a plate appearance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run Value: 0.40\n",
      "Win Probability: 63.18%\n",
      "Run Value (bad base_state): 0.12\n",
      "Inning 7: WP = 63.76%\n",
      "Inning 8: WP = 71.71%\n",
      "Inning 9: WP = 78.50%\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import math\n",
    "\n",
    "def load_run_expectancy(path):\n",
    "    re_dict = {}\n",
    "    with open(path, newline=\"\") as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        for row in reader:\n",
    "            key = (int(row[\"outs\"]), row[\"base_state\"])\n",
    "            re_dict[key] = float(row[\"expected_runs\"])\n",
    "    return re_dict\n",
    "\n",
    "def run_value(re, before, after, runs_scored):\n",
    "    key_before = (before[\"outs\"], before[\"base_state\"])\n",
    "    key_after = (after[\"outs\"], after[\"base_state\"])\n",
    "    re_before = re.get(key_before, 0.0)\n",
    "    re_after = re.get(key_after, 0.0)\n",
    "    return (re_after + runs_scored) - re_before\n",
    "\n",
    "def features_for_wp(state, cum_run_value):\n",
    "    return [\n",
    "        1.0,\n",
    "        state[\"inning\"],\n",
    "        int(state[\"top\"]),\n",
    "        state[\"score_diff\"],\n",
    "        cum_run_value,\n",
    "    ]\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def win_prob(beta, state, cum_run_value):\n",
    "    x = features_for_wp(state, cum_run_value)\n",
    "    z = sum(b * xi for b, xi in zip(beta, x))\n",
    "    return sigmoid(z)\n",
    "\n",
    "# SMOKE TEST\n",
    "RE_EXAMPLE = {\n",
    "    (1, \"100\"): 0.88,\n",
    "    (1, \"000\"): 0.28,\n",
    "}\n",
    "\n",
    "before = {\"inning\": 7, \"top\": True, \"score_diff\": -1, \"outs\": 1, \"base_state\": \"100\"}\n",
    "after  = {\"inning\": 7, \"top\": True, \"score_diff\": 0,  \"outs\": 1, \"base_state\": \"000\"}\n",
    "runs_scored = 1\n",
    "\n",
    "rv = run_value(RE_EXAMPLE, before, after, runs_scored)\n",
    "print(f\"Run Value: {rv:.2f}\")  # Should be (0.28 + 1) - 0.88 = 0.40\n",
    "\n",
    "beta = [0.2, 0.05, -0.05, 0.3, 0.1]  # Fake model weights\n",
    "wp = win_prob(beta, after, cum_run_value=rv)\n",
    "print(f\"Win Probability: {wp:.2%}\")\n",
    "\n",
    "# Edge case: missing base_state/out combo\n",
    "after_bad = after.copy()\n",
    "after_bad[\"base_state\"] = \"999\"  # Not in RE table\n",
    "rv_bad = run_value(RE_EXAMPLE, before, after_bad, runs_scored)\n",
    "print(\"Run Value (bad base_state):\", rv_bad)\n",
    "\n",
    "# Stress-ish: multiple inning WP updates\n",
    "cum_rv = 0.0\n",
    "for inning in range(7, 10):\n",
    "    state = {\"inning\": inning, \"top\": False, \"score_diff\": inning - 7, \"outs\": 1, \"base_state\": \"000\"}\n",
    "    cum_rv += 0.15\n",
    "    print(f\"Inning {inning}: WP = {win_prob(beta, state, cum_run_value=cum_rv):.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
